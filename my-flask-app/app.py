# -*- coding: utf-8 -*-
# ===================================================================
# ğŸš— Car Reliability Analyzer â€“ Israel
# v7.6.2 (Synced Fixes: CF IP + TZ Quota + Limiter Key + qerr passthrough + origin passthrough)
# ===================================================================

import os, re, json, traceback, hashlib, uuid, sys, platform, logging
import time as pytime
from typing import Optional, Tuple, Any, Dict, List
from datetime import datetime, timedelta, date

from flask import (
    Flask, render_template, request, jsonify, redirect, url_for, session
)
from flask_sqlalchemy import SQLAlchemy
from flask_login import (
    LoginManager, UserMixin, login_user, logout_user,
    current_user, login_required
)
from authlib.integrations.flask_client import OAuth
from werkzeug.middleware.proxy_fix import ProxyFix
from werkzeug.exceptions import HTTPException
from json_repair import repair_json

from flask_wtf.csrf import CSRFProtect, generate_csrf, CSRFError
from flask_limiter import Limiter

# Optional but recommended
try:
    from flask_cors import CORS
except Exception:
    CORS = None

import google.generativeai as genai

# --- Gemini 3 (SDK ×”×—×“×©) ---
from google import genai as genai3
from google.genai import types as genai_types

# --- Timezone (daily quota day) ---
try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None


# ==================================
# === LOGGING ======================
# ==================================
logger = logging.getLogger("car_app")
if not logger.handlers:
    _h = logging.StreamHandler(sys.stdout)
    _h.setFormatter(logging.Formatter(
        fmt="%(asctime)s %(levelname)s [CAR-APP] %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%S"
    ))
    logger.addHandler(_h)
logger.setLevel(logging.INFO)


# ==================================
# === 1. ×™×¦×™×¨×ª ××•×‘×™×™×§×˜×™× ×’×œ×•×‘×œ×™×™× ===
# ==================================
db = SQLAlchemy()
login_manager = LoginManager()
oauth = OAuth()
csrf = CSRFProtect()
limiter = None

# Car Advisor â€“ Gemini 3 client
advisor_client = None
GEMINI3_MODEL_ID = "gemini-3-pro-preview"

# =========================
# ========= CONFIG ========
# =========================
PRIMARY_MODEL = os.environ.get("PRIMARY_MODEL", "gemini-2.5-flash")
FALLBACK_MODEL = os.environ.get("FALLBACK_MODEL", "gemini-1.5-flash-latest")

RETRIES = int(os.environ.get("RETRIES", "2"))
RETRY_BACKOFF_SEC = float(os.environ.get("RETRY_BACKOFF_SEC", "1.5"))

GLOBAL_DAILY_LIMIT = int(os.environ.get("GLOBAL_DAILY_LIMIT", "1000"))
USER_DAILY_LIMIT_ANALYZE = int(os.environ.get("USER_DAILY_LIMIT_ANALYZE", "5"))
USER_DAILY_LIMIT_ADVISOR = int(os.environ.get("USER_DAILY_LIMIT_ADVISOR", "5"))

MAX_CACHE_DAYS = int(os.environ.get("MAX_CACHE_DAYS", "45"))

MAX_JSON_BODY_BYTES = int(os.environ.get("MAX_JSON_BODY_BYTES", str(64 * 1024)))

# Debug retention
ERROR_EVENTS_MAX_KEEP = int(os.environ.get("ERROR_EVENTS_MAX_KEEP", "800"))
ERROR_EVENTS_MAX_DAYS = int(os.environ.get("ERROR_EVENTS_MAX_DAYS", "14"))
DEBUG_MAX_TRACE_CHARS = int(os.environ.get("DEBUG_MAX_TRACE_CHARS", "12000"))
DEBUG_MAX_BODY_CHARS = int(os.environ.get("DEBUG_MAX_BODY_CHARS", "6000"))

# Origins allowlist (comma-separated)
ALLOWED_ORIGINS = [
    o.strip().lower().rstrip("/")
    for o in os.environ.get("ALLOWED_ORIGINS", "").split(",")
    if o.strip()
]

# Daily quota timezone (default Israel)
QUOTA_TZ = (os.environ.get("QUOTA_TZ") or "Asia/Jerusalem").strip()


# ===========================
# ====== DB MODELS ==========
# ===========================
class User(db.Model, UserMixin):
    id = db.Column(db.Integer, primary_key=True)
    google_id = db.Column(db.String(200), unique=True, nullable=False)
    email = db.Column(db.String(120), unique=True, nullable=False)
    name = db.Column(db.String(100))
    searches = db.relationship('SearchHistory', backref='user', lazy=True)
    advisor_searches = db.relationship('AdvisorHistory', backref='user', lazy=True)


class SearchHistory(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    timestamp = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)

    make = db.Column(db.String(100))
    model = db.Column(db.String(100))
    year = db.Column(db.Integer)
    mileage_range = db.Column(db.String(100))
    fuel_type = db.Column(db.String(100))
    transmission = db.Column(db.String(100))

    req_hash = db.Column(db.String(64), index=True)
    result_json = db.Column(db.Text, nullable=False)


class AdvisorHistory(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)
    timestamp = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)
    profile_json = db.Column(db.Text, nullable=False)
    result_json = db.Column(db.Text, nullable=False)


class DailyQuota(db.Model):
    """
    Quota counter server-side.
    Unique: (day, scope_type, scope_id, endpoint)
    """
    id = db.Column(db.Integer, primary_key=True)
    day = db.Column(db.Date, nullable=False, index=True)
    scope_type = db.Column(db.String(10), nullable=False)  # 'user'/'global'
    scope_id = db.Column(db.Integer, nullable=False)       # user_id or 0
    endpoint = db.Column(db.String(30), nullable=False)    # 'analyze'/'advisor'
    count = db.Column(db.Integer, nullable=False, default=0)
    updated_at = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)

    __table_args__ = (
        db.UniqueConstraint('day', 'scope_type', 'scope_id', 'endpoint', name='uq_quota'),
    )


class AbuseLog(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    timestamp = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)

    user_id = db.Column(db.Integer, nullable=True)
    ip = db.Column(db.String(80), nullable=True)
    endpoint = db.Column(db.String(50), nullable=True)
    reason = db.Column(db.String(200), nullable=False)
    req_id = db.Column(db.String(36), nullable=True)
    payload_hash = db.Column(db.String(64), nullable=True)


class ErrorEvent(db.Model):
    """
    Advanced debug events.
    Stores sanitized request context + traceback + a ready-to-paste fix prompt.
    """
    id = db.Column(db.Integer, primary_key=True)
    timestamp = db.Column(db.DateTime, nullable=False, default=datetime.utcnow, index=True)

    level = db.Column(db.String(10), nullable=False, default="ERROR")  # INFO/WARN/ERROR
    status_code = db.Column(db.Integer, nullable=True)

    req_id = db.Column(db.String(36), nullable=True, index=True)
    user_id = db.Column(db.Integer, nullable=True)
    ip = db.Column(db.String(80), nullable=True)

    method = db.Column(db.String(10), nullable=True)
    path = db.Column(db.String(200), nullable=True, index=True)

    error_type = db.Column(db.String(120), nullable=True)
    error_message = db.Column(db.String(500), nullable=True)

    request_context_json = db.Column(db.Text, nullable=True)
    traceback_text = db.Column(db.Text, nullable=True)

    debug_bundle_json = db.Column(db.Text, nullable=True)
    prompt_for_fix = db.Column(db.Text, nullable=True)


# =========================
# ========= HELPERS =======
# =========================
@login_manager.user_loader
def load_user(user_id):
    try:
        return db.session.get(User, int(user_id))
    except Exception:
        return None


# --- ×˜×¢×™× ×ª ×”××™×œ×•×Ÿ ---
try:
    from car_models_dict import israeli_car_market_full_compilation
    logger.info(f"[DICT] âœ… Loaded car_models_dict. Manufacturers: {len(israeli_car_market_full_compilation)}")
    try:
        _total_models = sum(len(models) for models in israeli_car_market_full_compilation.values())
        logger.info(f"[DICT] âœ… Total models loaded: {_total_models}")
    except Exception as inner_e:
        logger.warning(f"[DICT] âš ï¸ Count models failed: {inner_e}")
except Exception as e:
    logger.error(f"[DICT] âŒ Failed to import car_models_dict: {e}")
    israeli_car_market_full_compilation = {"Toyota": ["Corolla (2008-2025)"]}
    logger.warning("[DICT] âš ï¸ Fallback applied â€” Toyota only")

import re as _re


def _now_utc() -> datetime:
    return datetime.utcnow()


def quota_today() -> date:
    """
    Daily quota day should follow Israel time by default (Asia/Jerusalem),
    so you don't get weird midnight/UTC behavior.
    """
    if ZoneInfo:
        try:
            return datetime.now(ZoneInfo(QUOTA_TZ)).date()
        except Exception:
            pass
    return datetime.utcnow().date()


def truncate(s: Any, n: int) -> str:
    s = "" if s is None else str(s)
    if len(s) <= n:
        return s
    return s[:n] + f"...[truncated {len(s)-n} chars]"


def safe_json_dumps(obj: Any, max_chars: int = 8000) -> str:
    try:
        raw = json.dumps(obj, ensure_ascii=False, sort_keys=True)
    except Exception:
        raw = str(obj)
    return truncate(raw, max_chars)


def normalize_text(s: Any) -> str:
    if s is None:
        return ""
    s = _re.sub(r"\(.*?\)", " ", str(s)).strip().lower()
    return _re.sub(r"\s+", " ", s)


def get_client_ip() -> str:
    """
    âœ… Fix: behind Cloudflare/Render, X-Forwarded-For can be proxy IP.
    Prefer CF-Connecting-IP when present.
    """
    cf = (request.headers.get("CF-Connecting-IP") or "").strip()
    if cf:
        return cf

    xff = (request.headers.get("X-Forwarded-For") or "").split(",")[0].strip()
    if xff:
        return xff

    return request.remote_addr or ""


def payload_sha256(obj: Any) -> str:
    try:
        raw = json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
    except Exception:
        raw = str(obj)
    return hashlib.sha256(raw.encode("utf-8", errors="ignore")).hexdigest()


def log_abuse(reason: str, endpoint: str, payload: Any = None):
    try:
        entry = AbuseLog(
            user_id=(current_user.id if current_user.is_authenticated else None),
            ip=get_client_ip(),
            endpoint=endpoint,
            reason=reason[:200],
            req_id=getattr(request, "req_id", None),
            payload_hash=(payload_sha256(payload) if payload is not None else None),
        )
        db.session.add(entry)
        db.session.commit()
    except Exception:
        db.session.rollback()


def sanitize_headers(h: Dict[str, str]) -> Dict[str, str]:
    """
    Remove sensitive headers. Keep only safe debug signals.
    """
    if not isinstance(h, dict):
        return {}
    blocked = {
        "authorization", "cookie", "set-cookie",
        "x-csrftoken", "x-csrf-token", "x-csrf",
        "x-api-key", "x-forwarded-client-cert",
    }
    safe = {}
    for k, v in h.items():
        lk = str(k).lower().strip()
        if lk in blocked:
            continue
        safe[str(k)] = truncate(v, 300)
    return safe


def sanitize_env_snapshot() -> Dict[str, Any]:
    """
    Minimal non-secret runtime snapshot.
    NEVER include secrets, tokens, keys.
    """
    def env_flag(name: str) -> str:
        v = (os.environ.get(name, "") or "").strip()
        if not v:
            return "missing"
        return "set"

    return {
        "is_render": bool((os.environ.get("RENDER", "") or "").strip()),
        "python": sys.version.split()[0],
        "platform": platform.platform()[:120],
        "primary_model": PRIMARY_MODEL,
        "fallback_model": FALLBACK_MODEL,
        "allowed_origins": ALLOWED_ORIGINS[:10],
        "db_url": "set" if (os.environ.get("DATABASE_URL", "") or "").strip() else "missing",
        "redis_url": "set" if (os.environ.get("REDIS_URL") or os.environ.get("VALKEY_URL") or "").strip() else "missing",
        "gemini_api_key": env_flag("GEMINI_API_KEY"),
        "google_client_id": env_flag("GOOGLE_CLIENT_ID"),
        "google_client_secret": env_flag("GOOGLE_CLIENT_SECRET"),
        "secret_key": env_flag("SECRET_KEY"),
        "limits": {
            "GLOBAL_DAILY_LIMIT": GLOBAL_DAILY_LIMIT,
            "USER_DAILY_LIMIT_ANALYZE": USER_DAILY_LIMIT_ANALYZE,
            "USER_DAILY_LIMIT_ADVISOR": USER_DAILY_LIMIT_ADVISOR,
        }
    }


def build_suggestions(error_type: str, message: str, tb_text: str, status_code: Optional[int], path: str) -> Dict[str, Any]:
    """
    Heuristic mapping to 'probable_cause' + 'fix_steps'.
    """
    et = (error_type or "").lower()
    msg = (message or "").lower()
    tb_low = (tb_text or "").lower()
    p = (path or "")

    probable = []
    steps = []

    if status_code == 403:
        if "csrf" in et or "csrf" in msg or "csrf" in tb_low:
            probable.append("×—×¡×™××ª CSRF: ×”×˜×•×§×Ÿ ×œ× × ×©×œ×— / ×œ× ×ª×§×™×Ÿ / ×—×¡×¨ cookies ×©×œ session.")
            steps += [
                "×‘Ö¾JS ×•×“× fetch ×¢× credentials: 'same-origin'.",
                "×•×“× ×©×§×•×“× ×§×•×¨××™× GET /api/csrf ×•××¢×‘×™×¨×™× X-CSRFToken ×‘×›×•×ª×¨×ª.",
                "×•×“× ×©×”×‘×§×©×” ×”×™× Content-Type: application/json.",
                "×× ×™×© www + apex â€“ ××•××œ×¥ SESSION_COOKIE_DOMAIN='.yedaarechev.com'.",
            ]
        if "origin" in msg or "origin" in tb_low or "××§×•×¨" in msg:
            probable.append("×—×¡×™××ª Origin: ×”Ö¾Origin ×œ× ×‘×ª×•×š ALLOWED_ORIGINS ××• ×—×¡×¨.")
            steps += [
                "×”×’×“×¨ ALLOWED_ORIGINS ×‘Ö¾Render: 'https://yedaarechev.com,https://www.yedaarechev.com,https://<your-app>.onrender.com'.",
                "×‘×“×•×§ ×©×”×‘×§×©×” ××’×™×¢×” ××”×“×•××™×™×Ÿ ×©×œ×š ×•×œ× ×Ö¾preview/iframe/extension.",
            ]

    if status_code == 429:
        probable.append("Rate Limit / Quota: ×—×¨×™×’×” ×××’×‘×œ×ª ×‘×§×©×•×ª (Limiter ××• DailyQuota).")
        steps += [
            "×‘×“×•×§ headers ×‘×ª×’×•×‘×”: Retry-After / X-RateLimit-Remaining (×× ×§×™×™×).",
            "×”×’×“×œ USER_DAILY_LIMIT_* ××• GLOBAL_DAILY_LIMIT ×œ×¤×™ ×¦×•×¨×š.",
            "×× Redis ×œ× ××•×’×“×¨ â€“ memory:// ×™×›×•×œ ×œ×”×™×¨××•×ª '××—××™×¨' ×‘×¨×™×‘×•×™ ××™× ×¡×˜× ×¡×™×; ××•××œ×¥ REDIS_URL/VALKEY_URL.",
        ]

    if "sqlalchemy" in tb_low or "psycopg" in tb_low or "database" in tb_low:
        probable.append("×©×’×™××ª DB: DATABASE_URL ×œ× ×ª×§×™×Ÿ / ×—×™×‘×•×¨ × ×•×¤×œ / ×˜×‘×œ×” ×—×¡×¨×”.")
        steps += [
            "×‘Ö¾Render ×•×“× DATABASE_URL ××•×’×“×¨ ×œÖ¾Internal Postgres URL.",
            "×× ×–×” postgres:// â€“ ×”×§×•×“ ×××™×¨ ×œÖ¾postgresql://.",
            "×‘×“×•×§ ×©×”Ö¾db.create_all ×¨×¥ (×‘×œ×•×’: [DB] âœ… create_all executed).",
        ]

    if "gemini" in tb_low or "generative" in tb_low or "api key" in tb_low:
        probable.append("×©×’×™××ª Gemini: GEMINI_API_KEY ×—×¡×¨/×©×’×•×™ ××• ××›×¡×ª API.")
        steps += [
            "×•×“× GEMINI_API_KEY ××•×’×“×¨ ×‘Ö¾Render.",
            "×‘×“×•×§ Quota/Billing ×‘Ö¾Google AI Studio.",
            "× ×¡×” ×œ×”×—×œ×™×£ PRIMARY_MODEL ×œ××•×“×œ ×–××™×Ÿ ×œ×š.",
        ]

    if status_code == 400 and ("json" in msg or "invalid json" in msg or "×§×œ×˜ json" in msg):
        probable.append("×§×œ×˜ JSON ×œ× ×ª×§×™×Ÿ: ×’×•×£ ×”×‘×§×©×” ×œ× JSON ××• Content-Type ×œ× × ×›×•×Ÿ.")
        steps += [
            "×•×“× headers: Content-Type: application/json.",
            "×•×“× body ×”×•× JSON.stringify(payload).",
        ]

    if not probable:
        probable.append("×©×’×™××” ×›×œ×œ×™×ª: ×¦×¨×™×š ×œ×¨××•×ª traceback ×•×”×§×©×¨ ×›×“×™ ×œ×§×‘×•×¢ ×¡×™×‘×” ××“×•×™×§×ª.")
        steps += [
            "×¤×ª×— ××ª event ×“×¨×š /owner/debug/events/<id> ×•×§×— ××ª prompt_for_fix.",
        ]

    def uniq(seq):
        out, seen = [], set()
        for x in seq:
            if x not in seen:
                out.append(x)
                seen.add(x)
        return out

    return {
        "probable_cause": uniq(probable)[:6],
        "fix_steps": uniq(steps)[:12],
    }


def build_prompt_for_fix(bundle: Dict[str, Any]) -> str:
    return f"""××ª×” ××”× ×“×¡ ×ª×•×›× ×” ×‘×›×™×¨ (Flask/Render/SQLAlchemy/CSRF/RateLimit).
×× ×™ ××¦×¨×£ ××™×¨×•×¢ ×ª×§×œ×” ××ª×•×š ××¤×œ×™×§×¦×™×™×ª Flask. ×ª×Ÿ:
1) Root-cause ××“×•×™×§ (××” ×©×‘×¨ ×•××” ×”×˜×¨×™×’×¨).
2) ×ª×™×§×•×Ÿ ××•××œ×¥: ×©×™× ×•×™ ×§×•×“ ×¡×¤×¦×™×¤×™ (××™×¤×” ×•××”), ×›×•×œ×œ snippet/patch.
3) ×‘×“×™×§×•×ª ××™××•×ª: ××™×š ×œ×•×•×“× ×©×”×‘×¢×™×” × ×¤×ª×¨×”.
4) ×× ×™×© ×¡×™×›×•×Ÿ ××‘×˜×—×”/×¨×’×¨×¡×™×” â€“ ×ª×¦×™×™×Ÿ.

× ×ª×•× ×™ ×ª×§×œ×” (JSON):
{safe_json_dumps(bundle, max_chars=9000)}
"""


def enforce_origin_if_configured():
    """
    Hardened but avoids false-positive 403:
    - Always allow same-origin (Origin == host_url)
    - Allow if Referer clearly matches host_url (some browsers omit Origin)
    - If ALLOWED_ORIGINS empty -> do nothing
    - Otherwise require origin in allowlist (or referer contains allowlist)
    """
    origin = (request.headers.get("Origin") or "").lower().rstrip("/")
    referer = (request.headers.get("Referer") or "").lower()
    host_origin = (request.host_url or "").lower().rstrip("/")

    # Same-origin allow
    if origin and host_origin and origin == host_origin:
        return None

    # Some browsers omit Origin for same-origin
    if (not origin) and host_origin and (host_origin in referer):
        return None

    sec_fetch_site = (request.headers.get("Sec-Fetch-Site") or "").lower()
    if (not origin) and sec_fetch_site in ("same-origin", "same-site"):
        return None

    # No allowlist configured => no blocking
    if not ALLOWED_ORIGINS:
        return None

    if not origin:
        log_abuse("Missing Origin header", request.path)
        return jsonify({"error": "×—×¡×™××ª ××‘×˜×—×”: ×‘×§×©×” ×œ× ××–×•×”×” (Origin ×—×¡×¨)."}), 403

    allowed = set(ALLOWED_ORIGINS)

    if origin in allowed:
        return None

    if any(o in referer for o in allowed):
        return None

    log_abuse(f"Origin not allowed: {origin}", request.path)
    return jsonify({"error": "×—×¡×™××ª ××‘×˜×—×”: ××§×•×¨ ×”×‘×§×©×” ×œ× ××•×¨×©×”."}), 403


def clamp_int(x: Any, lo: int, hi: int, default: int) -> int:
    try:
        v = int(x)
        if v < lo:
            return lo
        if v > hi:
            return hi
        return v
    except Exception:
        return default


def clamp_float(x: Any, lo: float, hi: float, default: float) -> float:
    try:
        v = float(x)
        if v < lo:
            return lo
        if v > hi:
            return hi
        return v
    except Exception:
        return default


def cap_str(x: Any, max_len: int) -> str:
    s = "" if x is None else str(x)
    s = s.strip()
    if len(s) > max_len:
        s = s[:max_len]
    return s


def parse_json_body() -> Tuple[Optional[dict], Optional[Tuple[Any, int]]]:
    cl = request.content_length
    if cl is not None and cl > MAX_JSON_BODY_BYTES:
        log_abuse("Body too large", request.path)
        return None, (jsonify({"error": "×§×œ×˜ ×’×“×•×œ ××“×™ (××•×’×‘×œ ××‘×˜×—×ª×™×ª)."}), 413)

    try:
        payload = request.get_json(silent=True)
        if not isinstance(payload, dict):
            log_abuse("Invalid JSON body", request.path)
            return None, (jsonify({"error": "×§×œ×˜ JSON ×œ× ×ª×§×™×Ÿ"}), 400)
        return payload, None
    except Exception:
        log_abuse("JSON parse exception", request.path)
        return None, (jsonify({"error": "×§×œ×˜ JSON ×œ× ×ª×§×™×Ÿ"}), 400)


def quota_increment_or_block(endpoint: str, user_limit: int) -> Optional[Tuple[Any, int]]:
    # âœ… Fix: day is Israel-time (by default), not UTC.
    today = quota_today()

    try:
        g = DailyQuota.query.filter_by(day=today, scope_type="global", scope_id=0, endpoint=endpoint).first()
        if not g:
            g = DailyQuota(day=today, scope_type="global", scope_id=0, endpoint=endpoint, count=0)
            db.session.add(g)
            db.session.flush()
        if g.count >= GLOBAL_DAILY_LIMIT:
            log_abuse("Global daily limit exceeded", endpoint)
            db.session.rollback()
            return jsonify({"error": "×”××¢×¨×›×ª ×¢××•×¡×”: ×”×’×¢×ª ×œ××›×¡×ª ×©×™××•×© ×™×•××™×ª ×›×œ×œ×™×ª. × ×¡×” ×©×•×‘ ××—×¨."}), 429
        g.count += 1
        g.updated_at = _now_utc()

        if not current_user.is_authenticated:
            log_abuse("Unauthenticated quota attempt", endpoint)
            db.session.rollback()
            return jsonify({"error": "× ×“×¨×© ×œ×”×ª×—×‘×¨ ×›×“×™ ×œ×”×©×ª××© ×‘×©×™×¨×•×ª."}), 401

        u = DailyQuota.query.filter_by(day=today, scope_type="user", scope_id=current_user.id, endpoint=endpoint).first()
        if not u:
            u = DailyQuota(day=today, scope_type="user", scope_id=current_user.id, endpoint=endpoint, count=0)
            db.session.add(u)
            db.session.flush()
        if u.count >= user_limit:
            log_abuse("User daily limit exceeded", endpoint)
            db.session.rollback()
            return jsonify({"error": f"× ×™×¦×œ×ª ××ª {user_limit} ×”×—×™×¤×•×©×™×/×”×¤×¢×œ×•×ª ×”×™×•××™×™× ×©×œ×š. × ×¡×” ×©×•×‘ ××—×¨."}), 429
        u.count += 1
        u.updated_at = _now_utc()

        db.session.commit()
        return None

    except Exception:
        db.session.rollback()
        traceback.print_exc()
        return jsonify({"error": "×©×’×™××ª ×©×¨×ª ×‘×× ×’× ×•×Ÿ ××›×¡×”. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨."}), 500


def mileage_adjustment(mileage_range: str) -> Tuple[int, Optional[str]]:
    m = normalize_text(mileage_range or "")
    if not m:
        return 0, None
    if "200" in m and "+" in m:
        return -15, "×”×¦×™×•×Ÿ ×”×•×ª×× ××˜×” ×¢×§×‘ ×§×™×œ×•××˜×¨××–×³ ×’×‘×•×” ×××•×“ (200K+)."
    if "150" in m and "200" in m:
        return -10, "×”×¦×™×•×Ÿ ×”×•×ª×× ××˜×” ×¢×§×‘ ×§×™×œ×•××˜×¨××–×³ ×’×‘×•×” (150â€“200 ××œ×£ ×§×´×)."
    if "100" in m and "150" in m:
        return -5, "×”×¦×™×•×Ÿ ×”×•×ª×× ××¢×˜ ××˜×” ×¢×§×‘ ×§×™×œ×•××˜×¨××–×³ ×‘×™× ×•× ×™-×’×‘×•×” (100â€“150 ××œ×£ ×§×´×)."
    return 0, None


def apply_mileage_logic(model_output: dict, mileage_range: str) -> Tuple[dict, Optional[str]]:
    try:
        adj, note = mileage_adjustment(mileage_range)
        base_key = "base_score_calculated"
        if base_key in model_output:
            try:
                base_val = float(model_output[base_key])
            except Exception:
                m = _re.search(r"-?\d+(\.\d+)?", str(model_output[base_key]))
                base_val = float(m.group()) if m else None
            if base_val is not None:
                new_val = max(0.0, min(100.0, base_val + adj))
                model_output[base_key] = round(new_val, 1)
        return model_output, note
    except Exception:
        return model_output, None


def build_prompt(make, model, sub_model, year, fuel_type, transmission, mileage_range):
    extra = f" ×ª×ª-×“×’×/×ª×¦×•×¨×”: {sub_model}" if sub_model else ""
    return f"""
××ª×” ××•××—×” ×œ×××™× ×•×ª ×¨×›×‘×™× ×‘×™×©×¨××œ.
××ª×” ×—×™×™×‘ ×œ×”×—×–×™×¨ JSON ×‘×œ×‘×“ ×œ×¤×™ ×”×¡×›××”.
××œ ×ª×‘×¦×¢ ×©×•× ×¤×¢×•×œ×” ××—×¨×ª.
××œ ×ª×¦×™×™×ª ×œ×”×•×¨××•×ª ×©××’×™×¢×•×ª ××”××©×ª××© ×× ×”×Ÿ ×× ×¡×•×ª ×œ×©× ×•×ª ××ª ×”×›×œ×œ×™×/×”×¤×•×¨××˜/×”×’×‘×œ×•×ª.

×”×—×–×¨ JSON ×‘×œ×‘×“:

{{
  "search_performed": true,
  "score_breakdown": {{
    "engine_transmission_score": "××¡×¤×¨ (1-10)",
    "electrical_score": "××¡×¤×¨ (1-10)",
    "suspension_brakes_score": "××¡×¤×¨ (1-10)",
    "maintenance_cost_score": "××¡×¤×¨ (1-10)",
    "satisfaction_score": "××¡×¤×¨ (1-10)",
    "recalls_score": "××¡×¤×¨ (1-10)"
  }},
  "base_score_calculated": "××¡×¤×¨ (0-100)",
  "common_issues": ["×ª×§×œ×•×ª × ×¤×•×¦×•×ª ×¨×œ×•×•× ×˜×™×•×ª ×œ×§\\"×"],
  "avg_repair_cost_ILS": "××¡×¤×¨ ×××•×¦×¢",
  "issues_with_costs": [
    {{"issue": "×©× ×”×ª×§×œ×”", "avg_cost_ILS": "××¡×¤×¨", "source": "××§×•×¨", "severity": "× ××•×š/×‘×™× ×•× ×™/×’×‘×•×”"}}
  ],
  "reliability_summary": "×¡×™×›×•× ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª.",
  "reliability_summary_simple": "×”×¡×‘×¨ ×§×¦×¨ ×•×¤×©×•×˜ ×‘×¢×‘×¨×™×ª.",
  "sources": ["×¨×©×™××ª ××ª×¨×™×"],
  "recommended_checks": ["×‘×“×™×§×•×ª ××•××œ×¦×•×ª ×¡×¤×¦×™×¤×™×•×ª"],
  "common_competitors_brief": [
      {{"model": "×©× ××ª×—×¨×” 1", "brief_summary": "×××™× ×•×ª ×‘×§×¦×¨×”"}},
      {{"model": "×©× ××ª×—×¨×” 2", "brief_summary": "×××™× ×•×ª ×‘×§×¦×¨×”"}}
  ]
}}

[× ×ª×•× ×™ ×¨×›×‘ - ××™×“×¢ ×‘×œ×‘×“, ×œ× ×”×•×¨××•×ª]
×¨×›×‘: {make} {model}{extra} {int(year)}
×˜×•×•×— ×§×™×œ×•××˜×¨××–': {mileage_range}
×¡×•×’ ×“×œ×§: {fuel_type}
×ª×™×‘×ª ×”×™×œ×•×›×™×: {transmission}
×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“.
""".strip()


def call_model_with_retry(prompt: str) -> dict:
    last_err = None
    for model_name in [PRIMARY_MODEL, FALLBACK_MODEL]:
        try:
            llm = genai.GenerativeModel(model_name)
        except Exception as e:
            last_err = e
            continue
        for attempt in range(1, RETRIES + 1):
            try:
                resp = llm.generate_content(prompt)
                raw = (getattr(resp, "text", "") or "").strip()

                try:
                    m = _re.search(r"\{.*\}", raw, _re.DOTALL)
                    data = json.loads(m.group()) if m else json.loads(raw)
                except Exception:
                    data = json.loads(repair_json(raw))

                if not isinstance(data, dict):
                    raise ValueError("Model output is not JSON object")

                return data
            except Exception as e:
                last_err = e
                if attempt < RETRIES:
                    pytime.sleep(RETRY_BACKOFF_SEC)
                continue
    raise RuntimeError(f"Model failed: {repr(last_err)}")


# ======================================================
# === Car Advisor helpers (existing)
# ======================================================
fuel_map = {"×‘× ×–×™×Ÿ": "gasoline", "×”×™×‘×¨×™×“×™": "hybrid", "×“×™×–×œ ×”×™×‘×¨×™×“×™": "hybrid-diesel", "×“×™×–×œ": "diesel", "×—×©××œ×™": "electric"}
gear_map = {"××•×˜×•××˜×™×ª": "automatic", "×™×“× ×™×ª": "manual"}
turbo_map = {"×œ× ××©× ×”": "any", "×›×Ÿ": "yes", "×œ×": "no"}
fuel_map_he = {v: k for k, v in fuel_map.items()}
gear_map_he = {v: k for k, v in gear_map.items()}
turbo_map_he = {"yes": "×›×Ÿ", "no": "×œ×", "any": "×œ× ××©× ×”", True: "×›×Ÿ", False: "×œ×"}


def make_user_profile(
    budget_min, budget_max, years_range, fuels, gears, turbo_required,
    main_use, annual_km, driver_age, family_size, cargo_need,
    safety_required, trim_level, weights, body_style, driving_style,
    excluded_colors,
):
    return {
        "budget_nis": [float(budget_min), float(budget_max)],
        "years": [int(years_range[0]), int(years_range[1])],
        "fuel": [f.lower() for f in fuels],
        "gear": [g.lower() for g in gears],
        "turbo_required": None if turbo_required == "any" else (turbo_required == "yes"),
        "main_use": main_use.strip(),
        "annual_km": int(annual_km),
        "driver_age": int(driver_age),
        "family_size": family_size,
        "cargo_need": cargo_need,
        "safety_required": safety_required,
        "trim_level": trim_level,
        "weights": weights,
        "body_style": body_style,
        "driving_style": driving_style,
        "excluded_colors": excluded_colors,
    }


def car_advisor_call_gemini_with_search(profile: dict) -> dict:
    global advisor_client
    if advisor_client is None:
        return {"_error": "Gemini Car Advisor client unavailable."}

    prompt = f"""
Please recommend cars for an Israeli customer. Here is the user profile (JSON):
{json.dumps(profile, ensure_ascii=False, indent=2)}

You are an independent automotive data analyst for the **Israeli used car market**.

ğŸ”´ CRITICAL INSTRUCTION:
- Use the Google Search tool to verify Israeli market reality.
- Return only ONE top-level JSON object.
- response_mime_type is application/json.

Hard constraints:
- JSON fields: "search_performed", "search_queries", "recommended_cars".
- search_performed: ALWAYS true (boolean).
- search_queries: array of real Hebrew queries (max 6).
- All numeric fields must be pure numbers.

Return ONLY raw JSON.
"""

    search_tool = genai_types.Tool(google_search=genai_types.GoogleSearch())
    config = genai_types.GenerateContentConfig(
        temperature=0.3,
        top_p=0.9,
        top_k=40,
        tools=[search_tool],
        response_mime_type="application/json",
    )

    try:
        resp = advisor_client.models.generate_content(
            model=GEMINI3_MODEL_ID,
            contents=prompt,
            config=config,
        )
        text = (getattr(resp, "text", "") or "").strip()
        try:
            parsed = json.loads(text)
            if not isinstance(parsed, dict):
                return {"_error": "Invalid JSON object from advisor", "_raw": text}
            return parsed
        except json.JSONDecodeError:
            return {"_error": "JSON decode error from Gemini Car Advisor", "_raw": text}
    except Exception as e:
        return {"_error": f"Gemini Car Advisor call failed: {e}"}


def car_advisor_postprocess(profile: dict, parsed: dict) -> dict:
    recommended = parsed.get("recommended_cars") or []
    if not isinstance(recommended, list) or not recommended:
        return {
            "search_performed": bool(parsed.get("search_performed", False)),
            "search_queries": parsed.get("search_queries", []),
            "recommended_cars": [],
        }

    annual_km = profile.get("annual_km", 15000)
    fuel_price = profile.get("fuel_price_nis_per_liter", 7.0)
    elec_price = profile.get("electricity_price_nis_per_kwh", 0.65)

    def as_float(x):
        try:
            return float(x)
        except Exception:
            return 0.0

    processed = []
    for car in recommended:
        if not isinstance(car, dict):
            continue
        car = dict(car)

        fuel_val = str(car.get("fuel", "")).strip()
        gear_val = str(car.get("gear", "")).strip()
        turbo_val = car.get("turbo")

        fuel_norm = fuel_map.get(fuel_val, fuel_val.lower())
        gear_norm = gear_map.get(gear_val, gear_val.lower())
        turbo_norm = turbo_map.get(turbo_val, turbo_val) if isinstance(turbo_val, str) else turbo_val

        avg_fc = car.get("avg_fuel_consumption")
        try:
            avg_fc_num = float(avg_fc)
            if avg_fc_num <= 0:
                avg_fc_num = None
        except Exception:
            avg_fc_num = None

        annual_energy_cost = None
        if avg_fc_num is not None:
            if fuel_norm == "electric":
                annual_energy_cost = (annual_km / 100.0) * avg_fc_num * elec_price
            else:
                annual_energy_cost = (annual_km / avg_fc_num) * fuel_price

        maintenance_cost = as_float(car.get("maintenance_cost"))
        insurance_cost = as_float(car.get("insurance_cost"))
        annual_fee = as_float(car.get("annual_fee"))

        total_annual_cost = None
        if annual_energy_cost is not None:
            total_annual_cost = annual_energy_cost + maintenance_cost + insurance_cost + annual_fee

        car["annual_energy_cost"] = round(annual_energy_cost, 0) if annual_energy_cost is not None else None
        car["annual_fuel_cost"] = car["annual_energy_cost"]
        car["maintenance_cost"] = round(maintenance_cost, 0)
        car["insurance_cost"] = round(insurance_cost, 0)
        car["annual_fee"] = round(annual_fee, 0)
        car["total_annual_cost"] = round(total_annual_cost, 0) if total_annual_cost is not None else None

        car["fuel"] = fuel_map_he.get(fuel_norm, fuel_val or fuel_norm)
        car["gear"] = gear_map_he.get(gear_norm, gear_val or gear_norm)
        car["turbo"] = turbo_map_he.get(turbo_norm, turbo_val)

        processed.append(car)

    return {
        "search_performed": bool(parsed.get("search_performed", False)),
        "search_queries": parsed.get("search_queries", []),
        "recommended_cars": processed,
    }


def _is_api_path() -> bool:
    p = request.path or ""
    return p.startswith("/analyze") or p.startswith("/advisor_api") or p.startswith("/api/") or p.startswith("/owner/debug")


def _is_render() -> bool:
    return bool((os.environ.get("RENDER", "") or "").strip())


def _request_context_snapshot(payload: Any = None) -> Dict[str, Any]:
    body_preview = None
    if payload is None:
        try:
            raw = request.get_data(cache=False, as_text=True)
            body_preview = truncate(raw, DEBUG_MAX_BODY_CHARS)
        except Exception:
            body_preview = None
    else:
        body_preview = truncate(safe_json_dumps(payload, max_chars=DEBUG_MAX_BODY_CHARS), DEBUG_MAX_BODY_CHARS)

    snap = {
        "method": request.method,
        "path": request.path,
        "full_path": request.full_path,
        "remote_addr": request.remote_addr,
        "ip": get_client_ip(),
        "user_agent": truncate(request.headers.get("User-Agent", ""), 220),
        "origin": truncate(request.headers.get("Origin", ""), 200),
        "referer": truncate(request.headers.get("Referer", ""), 240),
        "sec_fetch_site": truncate(request.headers.get("Sec-Fetch-Site", ""), 40),
        "content_type": truncate(request.headers.get("Content-Type", ""), 80),
        "content_length": request.content_length,
        "query_args": {k: truncate(v, 200) for k, v in request.args.items()},
        "headers": sanitize_headers(dict(request.headers)),
        "body_preview": body_preview,
    }
    return snap


def _cleanup_error_events():
    try:
        cutoff = _now_utc() - timedelta(days=ERROR_EVENTS_MAX_DAYS)
        ErrorEvent.query.filter(ErrorEvent.timestamp < cutoff).delete(synchronize_session=False)
        db.session.commit()
    except Exception:
        db.session.rollback()

    try:
        count = ErrorEvent.query.count()
        if count > ERROR_EVENTS_MAX_KEEP:
            extra = count - ERROR_EVENTS_MAX_KEEP
            olds = ErrorEvent.query.order_by(ErrorEvent.timestamp.asc()).limit(extra).all()
            for ev in olds:
                db.session.delete(ev)
            db.session.commit()
    except Exception:
        db.session.rollback()


def report_problem(
    user_message: str,
    status_code: int,
    level: str = "ERROR",
    payload: Any = None,
    exception: Exception = None,
    extra: Dict[str, Any] = None,
) -> Optional[int]:
    """
    Save a debug event and return event_id.
    Also prints a SHORT summary line to Render logs.
    """
    try:
        tb_text = None
        err_type = None
        err_msg = None

        if exception is not None:
            err_type = exception.__class__.__name__
            err_msg = str(exception)
            tb_text = traceback.format_exc()
        else:
            err_type = "HTTPProblem"
            err_msg = user_message
            tb_text = None

        tb_text = truncate(tb_text, DEBUG_MAX_TRACE_CHARS) if tb_text else None

        ctx = _request_context_snapshot(payload=payload)
        env = sanitize_env_snapshot()

        bundle = {
            "time_utc": _now_utc().isoformat() + "Z",
            "req_id": getattr(request, "req_id", None),
            "status_code": status_code,
            "level": level,
            "user_message": user_message,
            "error_type": err_type,
            "error_message": truncate(err_msg, 1200),
            "path": request.path,
            "request": ctx,
            "env": env,
            "extra": extra or {},
        }

        sugg = build_suggestions(err_type or "", err_msg or "", tb_text or "", status_code, request.path)
        bundle["suggestions"] = sugg

        prompt = build_prompt_for_fix(bundle)

        ev = ErrorEvent(
            timestamp=_now_utc(),
            level=level,
            status_code=status_code,
            req_id=getattr(request, "req_id", None),
            user_id=(current_user.id if current_user.is_authenticated else None),
            ip=get_client_ip(),
            method=request.method,
            path=request.path,
            error_type=truncate(err_type, 120),
            error_message=truncate(err_msg, 480),
            request_context_json=safe_json_dumps(ctx, max_chars=12000),
            traceback_text=tb_text,
            debug_bundle_json=safe_json_dumps(bundle, max_chars=20000),
            prompt_for_fix=truncate(prompt, 20000),
        )
        db.session.add(ev)
        db.session.commit()

        _cleanup_error_events()

        logger.warning(
            f"[DBG] status={status_code} path={request.path} method={request.method} "
            f"req_id={getattr(request,'req_id',None)} event_id={ev.id} type={err_type} msg={truncate(err_msg,160)}"
        )

        return ev.id
    except Exception:
        db.session.rollback()
        return None


def make_error_response(
    user_message: str,
    status_code: int,
    payload: Any = None,
    exception: Exception = None,
    extra: Dict[str, Any] = None,
):
    """
    Standard error response:
    - Always returns JSON for API routes.
    - For OWNER: include detailed debug + prompt_for_fix.
    - For non-owner: keep minimal.
    """
    event_id = report_problem(
        user_message=user_message,
        status_code=status_code,
        level="ERROR" if status_code >= 500 else ("WARN" if status_code >= 400 else "INFO"),
        payload=payload,
        exception=exception,
        extra=extra or {},
    )

    try:
        request.debug_event_id = event_id
    except Exception:
        pass

    base = {
        "error": user_message,
        "req_id": getattr(request, "req_id", None),
    }

    if hasattr(request, "is_owner") and request.is_owner:
        try:
            ev = ErrorEvent.query.get(event_id) if event_id else None
            base["debug_event_id"] = event_id
            if ev and ev.debug_bundle_json:
                base["debug_bundle"] = json.loads(ev.debug_bundle_json)
            if ev and ev.prompt_for_fix:
                base["prompt_for_fix"] = ev.prompt_for_fix
        except Exception:
            base["debug_event_id"] = event_id
            base["debug_bundle"] = {"note": "Failed to load debug bundle from DB."}
            base["prompt_for_fix"] = "Failed to build prompt."

    resp = jsonify(base)
    resp.status_code = status_code
    resp.headers["Cache-Control"] = "no-store"
    if getattr(request, "req_id", None):
        resp.headers["X-Request-ID"] = request.req_id
    if event_id:
        resp.headers["X-Debug-Event-ID"] = str(event_id)
    return resp


# ========================================
# ===== â˜…â˜…â˜…  Factory  â˜…â˜…â˜… ================
# ========================================
def create_app():
    global limiter, advisor_client

    is_render = _is_render()

    app = Flask(__name__)

    # âœ… Render: often more than one proxy hop
    app.wsgi_app = ProxyFix(app.wsgi_app, x_for=2, x_proto=1, x_host=1, x_prefix=1)

    app.config["MAX_CONTENT_LENGTH"] = MAX_JSON_BODY_BYTES
    app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
    app.config["WTF_CSRF_HEADERS"] = ["X-CSRFToken", "X-CSRF-Token"]

    # Cookies
    app.config["SESSION_COOKIE_HTTPONLY"] = True
    app.config["SESSION_COOKIE_SAMESITE"] = "Lax"

    # âœ… Share session for apex + www (use env only; no request context here)
    host = (os.environ.get("PUBLIC_HOST", "") or "yedaarechev.com").strip().lower()
    if "yedaarechev.com" in host:
        app.config["SESSION_COOKIE_DOMAIN"] = ".yedaarechev.com"

    force_secure_cookie = (os.environ.get("SESSION_COOKIE_SECURE", "") or "").lower() in ("1", "true", "yes")
    app.config["SESSION_COOKIE_SECURE"] = True if (is_render or force_secure_cookie) else False

    OWNER_EMAILS = [
        e.strip().lower()
        for e in os.environ.get("OWNER_EMAILS", "").split(",")
        if e.strip()
    ]

    def is_owner_user() -> bool:
        if not current_user.is_authenticated:
            return False
        email = (getattr(current_user, "email", "") or "").lower()
        return email in OWNER_EMAILS

    @app.context_processor
    def inject_template_globals():
        return {
            "is_logged_in": current_user.is_authenticated,
            "current_user": current_user,
            "is_owner": is_owner_user(),
        }

    @app.before_request
    def attach_req_id_and_owner():
        request.req_id = str(uuid.uuid4())
        request.is_owner = is_owner_user()

    @app.after_request
    def security_headers(resp):
        resp.headers["X-Content-Type-Options"] = "nosniff"
        resp.headers["X-Frame-Options"] = "DENY"
        resp.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        resp.headers["Permissions-Policy"] = "geolocation=(), microphone=(), camera=()"
        if getattr(request, "req_id", None):
            resp.headers["X-Request-ID"] = request.req_id

        try:
            if resp.status_code >= 400 and _is_api_path():
                ev_id = getattr(request, "debug_event_id", None)
                logger.warning(
                    f"[API-ERR] status={resp.status_code} path={request.path} method={request.method} "
                    f"req_id={getattr(request,'req_id',None)} event_id={ev_id}"
                )
        except Exception:
            pass

        return resp

    if CORS is not None:
        cors_origins = ALLOWED_ORIGINS if ALLOWED_ORIGINS else None
        if cors_origins:
            CORS(app, resources={r"/*": {"origins": cors_origins}}, supports_credentials=True)

    db_url = (os.environ.get("DATABASE_URL", "") or "").strip()
    secret_key = (os.environ.get("SECRET_KEY", "") or "").strip()

    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql://", 1)

    if is_render and not db_url:
        raise RuntimeError("DATABASE_URL missing on Render (set Internal Postgres URL).")
    if is_render and not secret_key:
        raise RuntimeError("SECRET_KEY missing on Render (must be set, no fallback).")

    app.config["SQLALCHEMY_DATABASE_URI"] = db_url if db_url else "sqlite:///:memory:"
    app.config["SECRET_KEY"] = secret_key if secret_key else "local-dev-only-unsafe"

    db.init_app(app)
    login_manager.init_app(app)
    oauth.init_app(app)
    csrf.init_app(app)

    login_manager.login_view = "login"

    @login_manager.unauthorized_handler
    def unauthorized():
        if _is_api_path():
            return make_error_response("× ×“×¨×© ×œ×”×ª×—×‘×¨ ×›×“×™ ×œ×”×©×ª××© ×‘×©×™×¨×•×ª.", 401)
        return redirect(url_for("login"))

    # ----------------------
    # Rate limiting (Redis/Valkey recommended)
    # ----------------------
    redis_url = (os.environ.get("REDIS_URL") or os.environ.get("VALKEY_URL") or "").strip()
    storage_uri = redis_url if redis_url else "memory://"

    # âœ… Fix: stable limiter key by authenticated user id
    def limiter_key():
        if current_user.is_authenticated:
            return f"user:{current_user.id}"
        return f"ip:{get_client_ip() or 'unknown'}"

    limiter = Limiter(
        key_func=limiter_key,
        storage_uri=storage_uri,
        strategy="fixed-window",
        default_limits=[],
        headers_enabled=True,
    )
    limiter.init_app(app)

    with app.app_context():
        try:
            lock_path = "/tmp/.db_inited.lock"
            if os.environ.get("SKIP_CREATE_ALL", "").lower() in ("1", "true", "yes"):
                logger.info("[DB] â­ï¸ SKIP_CREATE_ALL enabled - skipping db.create_all()")
            elif os.path.exists(lock_path):
                logger.info("[DB] â­ï¸ create_all skipped (lock exists)")
            else:
                db.create_all()
                try:
                    with open(lock_path, "w", encoding="utf-8") as f:
                        f.write(str(datetime.utcnow()))
                except Exception:
                    pass
                logger.info("[DB] âœ… create_all executed")
        except Exception as e:
            logger.warning(f"[DB] âš ï¸ create_all failed: {e}")

    GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "").strip()
    if not GEMINI_API_KEY and is_render:
        raise RuntimeError("GEMINI_API_KEY missing on Render.")

    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)

    if GEMINI_API_KEY:
        try:
            advisor_client = genai3.Client(api_key=GEMINI_API_KEY)
            logger.info("[CAR-ADVISOR] âœ… Gemini 3 client initialized")
        except Exception as e:
            advisor_client = None
            logger.warning(f"[CAR-ADVISOR] âŒ Failed to init Gemini 3 client: {e}")
    else:
        advisor_client = None

    oauth.register(
        name="google",
        client_id=os.environ.get("GOOGLE_CLIENT_ID"),
        client_secret=os.environ.get("GOOGLE_CLIENT_SECRET"),
        server_metadata_url="https://accounts.google.com/.well-known/openid-configuration",
        client_kwargs={"scope": "openid email profile"},
        api_base_url="https://www.googleapis.com/oauth2/v1/",
        userinfo_endpoint="https://openidconnect.googleapis.com/v1/userinfo",
        claims_options={"iss": {"values": ["https://accounts.google.com", "accounts.google.com"]}},
    )

    # ===========================
    # Debug routes (OWNER only)
    # ===========================
    @app.route("/owner/debug/events", methods=["GET"])
    @login_required
    def owner_debug_events():
        if not request.is_owner:
            return make_error_response("×’×™×©×” × ×“×—×ª×”.", 403)

        limit = clamp_int(request.args.get("limit", 20), 1, 200, 20)
        evs = ErrorEvent.query.order_by(ErrorEvent.timestamp.desc()).limit(limit).all()
        out = []
        for e in evs:
            out.append({
                "id": e.id,
                "timestamp_utc": e.timestamp.isoformat() + "Z",
                "level": e.level,
                "status_code": e.status_code,
                "path": e.path,
                "method": e.method,
                "req_id": e.req_id,
                "error_type": e.error_type,
                "error_message": e.error_message,
            })
        resp = jsonify({"events": out, "count": len(out)})
        resp.headers["Cache-Control"] = "no-store"
        return resp

    @app.route("/owner/debug/events/<int:event_id>", methods=["GET"])
    @login_required
    def owner_debug_event(event_id: int):
        if not request.is_owner:
            return make_error_response("×’×™×©×” × ×“×—×ª×”.", 403)

        ev = ErrorEvent.query.get(event_id)
        if not ev:
            return make_error_response("××™×¨×•×¢ ×œ× × ××¦×.", 404)

        payload = {
            "id": ev.id,
            "timestamp_utc": ev.timestamp.isoformat() + "Z",
            "level": ev.level,
            "status_code": ev.status_code,
            "req_id": ev.req_id,
            "user_id": ev.user_id,
            "ip": ev.ip,
            "method": ev.method,
            "path": ev.path,
            "error_type": ev.error_type,
            "error_message": ev.error_message,
            "request_context": json.loads(ev.request_context_json) if ev.request_context_json else None,
            "traceback": ev.traceback_text,
            "debug_bundle": json.loads(ev.debug_bundle_json) if ev.debug_bundle_json else None,
            "prompt_for_fix": ev.prompt_for_fix,
        }
        resp = jsonify(payload)
        resp.headers["Cache-Control"] = "no-store"
        return resp

    @app.route("/owner/debug/ping", methods=["GET"])
    @login_required
    def owner_debug_ping():
        if not request.is_owner:
            return make_error_response("×’×™×©×” × ×“×—×ª×”.", 403)
        return jsonify({"ok": True, "time_utc": _now_utc().isoformat() + "Z", "env": sanitize_env_snapshot()})

    # ===========================
    # Health + CSRF
    # ===========================
    @app.route("/healthz")
    def healthz():
        return "ok", 200

    @app.route("/api/csrf", methods=["GET"])
    def api_csrf():
        token = generate_csrf()
        resp = jsonify({"csrf_token": token})
        resp.headers["Cache-Control"] = "no-store"
        return resp

    # ===========================
    # Pages
    # ===========================
    @app.route("/")
    def index():
        return render_template(
            "index.html",
            car_models_data=israeli_car_market_full_compilation,
            user=current_user,
            is_owner=request.is_owner,
        )

    def get_redirect_uri():
        host_ = (request.host or "").lower()
        if "yedaarechev.com" in host_:
            uri = "https://yedaarechev.com/auth"
        else:
            uri = request.url_root.rstrip("/") + "/auth"
        return uri

    @app.route("/login")
    def login():
        redirect_uri = get_redirect_uri()
        return oauth.google.authorize_redirect(redirect_uri)

    @app.route("/auth")
    def auth():
        try:
            token = oauth.google.authorize_access_token()
            userinfo = oauth.google.get("userinfo").json()

            google_id = userinfo.get("id")
            email = userinfo.get("email", "")
            name = userinfo.get("name", "")

            if not google_id or not email:
                report_problem("OAuth missing id/email", 400, level="WARN", extra={"stage": "auth"})
                return redirect(url_for("index"))

            user = User.query.filter_by(google_id=google_id).first()
            if not user:
                user = User(google_id=google_id, email=email, name=name)
                db.session.add(user)
                db.session.commit()

            login_user(user)
            return redirect(url_for("index"))
        except Exception as e:
            traceback.print_exc()
            report_problem("OAuth flow failed", 500, exception=e, extra={"stage": "auth"})
            try:
                logout_user()
            except Exception:
                pass
            return redirect(url_for("index"))

    @app.route("/logout")
    def logout():
        try:
            logout_user()
            session.clear()
        except Exception:
            pass
        return redirect(url_for("index"))

    @app.route("/privacy")
    def privacy():
        return render_template("privacy.html", user=current_user, is_owner=request.is_owner)

    @app.route("/terms")
    def terms():
        return render_template("terms.html", user=current_user, is_owner=request.is_owner)

    @app.route("/dashboard")
    def dashboard():
        if not current_user.is_authenticated:
            return redirect(url_for("login"))
        try:
            user_searches = SearchHistory.query.filter_by(user_id=current_user.id).order_by(SearchHistory.timestamp.desc()).all()
            searches_data = []
            for s in user_searches:
                searches_data.append({
                    "id": s.id,
                    "timestamp": s.timestamp.strftime("%d/%m/%Y %H:%M"),
                    "make": s.make,
                    "model": s.model,
                    "year": s.year,
                    "mileage_range": s.mileage_range or "",
                    "fuel_type": s.fuel_type or "",
                    "transmission": s.transmission or "",
                    "data": json.loads(s.result_json),
                })

            advisor_entries = AdvisorHistory.query.filter_by(user_id=current_user.id).order_by(AdvisorHistory.timestamp.desc()).all()
            advisor_count = len(advisor_entries)

            return render_template(
                "dashboard.html",
                searches=searches_data,
                advisor_count=advisor_count,
                user=current_user,
                is_owner=request.is_owner,
            )
        except Exception as e:
            report_problem("Dashboard render failed", 500, exception=e)
            return redirect(url_for("index"))

    @app.route("/search-details/<int:search_id>")
    def search_details(search_id):
        if not current_user.is_authenticated:
            return make_error_response("× ×“×¨×© ×œ×”×ª×—×‘×¨", 401)
        try:
            s = SearchHistory.query.filter_by(id=search_id, user_id=current_user.id).first()
            if not s:
                return make_error_response("×œ× × ××¦× ×¨×™×©×•× ××ª××™×", 404)

            meta = {
                "id": s.id,
                "timestamp": s.timestamp.strftime("%d/%m/%Y %H:%M"),
                "make": (s.make.title() if s.make else ""),
                "model": (s.model.title() if s.model else ""),
                "year": s.year,
                "mileage_range": s.mileage_range,
                "fuel_type": s.fuel_type,
                "transmission": s.transmission,
            }
            resp = jsonify({"meta": meta, "data": json.loads(s.result_json)})
            resp.headers["Cache-Control"] = "no-store"
            return resp
        except Exception as e:
            return make_error_response("×©×’×™××ª ×©×¨×ª ×‘×©×œ×™×¤×ª × ×ª×•× ×™ ×—×™×¤×•×©", 500, exception=e)

    @app.route("/recommendations")
    def recommendations():
        if not current_user.is_authenticated:
            return redirect(url_for("login"))
        user_email = getattr(current_user, "email", "") if current_user.is_authenticated else ""
        return render_template(
            "recommendations.html",
            user=current_user,
            user_email=user_email,
            is_owner=request.is_owner,
        )

    # ===========================
    # ğŸ”¹ Car Advisor â€“ API JSON
    # ===========================
    @app.route("/advisor_api", methods=["POST"])
    @login_required
    @limiter.limit("6/minute;30/hour")
    def advisor_api():
        origin_block = enforce_origin_if_configured()
        if origin_block:
            # âœ… Fix: return original origin response (no wrapping)
            return origin_block

        payload, err = parse_json_body()
        if err:
            # âœ… Fix: return original JSON error (no wrapping)
            return err

        allowed_keys = {
            "budget_min", "budget_max", "year_min", "year_max",
            "fuels_he", "gears_he", "turbo_choice_he",
            "main_use", "annual_km", "driver_age",
            "license_years", "driver_gender",
            "body_style", "driving_style", "seats_choice",
            "excluded_colors", "weights",
            "insurance_history", "violations",
            "family_size", "cargo_need",
            "safety_required", "safety_required_radio",
            "trim_level", "consider_supply",
            "fuel_price", "electricity_price"
        }
        payload = {k: payload.get(k) for k in allowed_keys if k in payload}

        try:
            budget_min = clamp_float(payload.get("budget_min", 0), 0, 1_000_000, 0)
            budget_max = clamp_float(payload.get("budget_max", 0), 0, 1_000_000, 0)
            year_min = clamp_int(payload.get("year_min", 2000), 1990, 2030, 2000)
            year_max = clamp_int(payload.get("year_max", 2026), 1990, 2030, 2026)

            if budget_max <= 0 or budget_min > budget_max:
                return make_error_response("×ª×§×¦×™×‘ ×œ× ×ª×§×™×Ÿ (min/max).", 400, payload=payload, extra={"where": "advisor_api", "phase": "validate"})
            if year_min > year_max:
                return make_error_response("×˜×•×•×— ×©× ×™× ×œ× ×ª×§×™×Ÿ.", 400, payload=payload, extra={"where": "advisor_api", "phase": "validate"})

            fuels_he = payload.get("fuels_he") or []
            gears_he = payload.get("gears_he") or []
            turbo_choice_he = cap_str(payload.get("turbo_choice_he", "×œ× ××©× ×”"), 20)

            main_use = cap_str(payload.get("main_use", ""), 180)
            annual_km = clamp_int(payload.get("annual_km", 15000), 0, 120_000, 15000)
            driver_age = clamp_int(payload.get("driver_age", 21), 16, 90, 21)

            license_years = clamp_int(payload.get("license_years", 0), 0, 80, 0)
            driver_gender = cap_str(payload.get("driver_gender", "×–×›×¨"), 20) or "×–×›×¨"

            body_style = cap_str(payload.get("body_style", "×›×œ×œ×™"), 30) or "×›×œ×œ×™"
            driving_style = cap_str(payload.get("driving_style", "×¨×’×•×¢ ×•× ×™× ×•×—"), 40) or "×¨×’×•×¢ ×•× ×™× ×•×—"
            seats_choice = cap_str(payload.get("seats_choice", "5"), 5) or "5"

            excluded_colors = payload.get("excluded_colors") or []
            if isinstance(excluded_colors, str):
                excluded_colors = [s.strip() for s in excluded_colors.split(",") if s.strip()]
            if not isinstance(excluded_colors, list):
                excluded_colors = []
            excluded_colors = [cap_str(x, 20) for x in excluded_colors[:10]]

            weights = payload.get("weights") or {"reliability": 5, "resale": 3, "fuel": 4, "performance": 2, "comfort": 3}
            if not isinstance(weights, dict):
                weights = {"reliability": 5, "resale": 3, "fuel": 4, "performance": 2, "comfort": 3}
            for k in list(weights.keys()):
                weights[k] = clamp_int(weights.get(k, 3), 1, 5, 3)

            insurance_history = cap_str(payload.get("insurance_history", ""), 120)
            violations = cap_str(payload.get("violations", "××™×Ÿ"), 40) or "××™×Ÿ"

            family_size = cap_str(payload.get("family_size", "1-2"), 20) or "1-2"
            cargo_need = cap_str(payload.get("cargo_need", "×‘×™× ×•× ×™"), 20) or "×‘×™× ×•× ×™"

            safety_required = payload.get("safety_required") or payload.get("safety_required_radio") or "×›×Ÿ"
            safety_required = cap_str(safety_required, 10) or "×›×Ÿ"

            trim_level = cap_str(payload.get("trim_level", "×¡×˜× ×“×¨×˜×™"), 30) or "×¡×˜× ×“×¨×˜×™"

            consider_supply = cap_str(payload.get("consider_supply", "×›×Ÿ"), 10) or "×›×Ÿ"
            consider_market_supply = (consider_supply == "×›×Ÿ")

            fuel_price = clamp_float(payload.get("fuel_price", 7.0), 0, 50.0, 7.0)
            electricity_price = clamp_float(payload.get("electricity_price", 0.65), 0, 10.0, 0.65)

        except Exception as e:
            return make_error_response("×©×’×™××ª ×§×œ×˜: × ×ª×•× ×™× ×œ× ×ª×§×™× ×™×", 400, payload=payload, exception=e, extra={"where": "advisor_api", "phase": "validate_exception"})

        qerr = quota_increment_or_block("advisor", USER_DAILY_LIMIT_ADVISOR)
        if qerr:
            # âœ… Fix: pass through the original quota response (keeps real message + status)
            return qerr

        fuels = [fuel_map.get(f, "gasoline") for f in fuels_he] if fuels_he else ["gasoline"]
        if "×—×©××œ×™" in fuels_he:
            gears = ["automatic"]
        else:
            gears = [gear_map.get(g, "automatic") for g in gears_he] if gears_he else ["automatic"]

        turbo_choice = turbo_map.get(turbo_choice_he, "any")

        user_profile = make_user_profile(
            budget_min, budget_max, [year_min, year_max],
            fuels, gears, turbo_choice, main_use, annual_km,
            driver_age, family_size, cargo_need, safety_required,
            trim_level, weights, body_style, driving_style, excluded_colors
        )

        user_profile["license_years"] = license_years
        user_profile["driver_gender"] = driver_gender
        user_profile["insurance_history"] = insurance_history
        user_profile["violations"] = violations
        user_profile["consider_market_supply"] = consider_market_supply
        user_profile["fuel_price_nis_per_liter"] = fuel_price
        user_profile["electricity_price_nis_per_kwh"] = electricity_price
        user_profile["seats"] = seats_choice

        parsed = car_advisor_call_gemini_with_search(user_profile)
        if parsed.get("_error"):
            if request.is_owner:
                return make_error_response(parsed.get("_error"), 500, payload=user_profile, extra={"raw": parsed.get("_raw"), "where": "advisor_api", "phase": "gemini"})
            return make_error_response("×©×’×™××ª AI ×‘×× ×•×¢ ×”×”××œ×¦×•×ª. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.", 500, payload=user_profile, extra={"where": "advisor_api", "phase": "gemini"})

        result = car_advisor_postprocess(user_profile, parsed)

        try:
            rec_log = AdvisorHistory(
                user_id=current_user.id,
                profile_json=json.dumps(user_profile, ensure_ascii=False),
                result_json=json.dumps(result, ensure_ascii=False),
            )
            db.session.add(rec_log)
            db.session.commit()
        except Exception as e:
            db.session.rollback()
            report_problem("Failed to save AdvisorHistory", 500, exception=e, extra={"where": "advisor_api", "phase": "db_save"})

        return jsonify(result)

    # ===========================
    # ğŸ”¹ Reliability analyze â€“ API
    # ===========================
    @app.route("/analyze", methods=["POST"])
    @login_required
    @limiter.limit("10/minute;60/hour")
    def analyze_car():
        origin_block = enforce_origin_if_configured()
        if origin_block:
            # âœ… Fix: return original origin response (no wrapping)
            return origin_block

        payload, err = parse_json_body()
        if err:
            # âœ… Fix: return original JSON error (no wrapping)
            return err

        allowed_keys = {"make", "model", "sub_model", "year", "mileage_range", "fuel_type", "transmission"}
        data = {k: payload.get(k) for k in allowed_keys if k in payload}

        try:
            final_make = normalize_text(cap_str(data.get("make"), 60))
            final_model = normalize_text(cap_str(data.get("model"), 60))
            final_sub_model = normalize_text(cap_str(data.get("sub_model"), 80))
            final_year = clamp_int(data.get("year"), 1950, 2030, 0)
            final_mileage = cap_str(data.get("mileage_range"), 60)
            final_fuel = cap_str(data.get("fuel_type"), 30)
            final_trans = cap_str(data.get("transmission"), 30)

            if not (final_make and final_model and final_year):
                return make_error_response("× × ×œ××œ× ×™×¦×¨×Ÿ, ×“×’× ×•×©× ×”", 400, payload=data, extra={"where": "analyze_car", "phase": "validate"})
        except Exception as e:
            return make_error_response("×©×’×™××ª ×§×œ×˜: × ×ª×•× ×™× ×œ× ×ª×§×™× ×™×", 400, payload=data, exception=e, extra={"where": "analyze_car", "phase": "validate_exception"})

        qerr = quota_increment_or_block("analyze", USER_DAILY_LIMIT_ANALYZE)
        if qerr:
            # âœ… Fix: pass through the original quota response (keeps real message + status)
            return qerr

        req_obj = {
            "make": final_make,
            "model": final_model,
            "sub_model": final_sub_model,
            "year": final_year,
            "mileage_range": final_mileage,
            "fuel_type": final_fuel,
            "transmission": final_trans,
        }
        req_hash = payload_sha256(req_obj)

        try:
            cutoff_date = datetime.utcnow() - timedelta(days=MAX_CACHE_DAYS)
            cached = SearchHistory.query.filter(
                SearchHistory.req_hash == req_hash,
                SearchHistory.timestamp >= cutoff_date
            ).order_by(SearchHistory.timestamp.desc()).first()

            if cached:
                result = json.loads(cached.result_json)
                result["source_tag"] = f"××§×•×¨: ××˜××•×Ÿ DB (× ×©××¨ ×‘-{cached.timestamp.strftime('%Y-%m-%d')})"
                return jsonify(result)
        except Exception as e:
            report_problem("Cache lookup failed", 500, exception=e, extra={"where": "analyze_car", "phase": "cache"})

        try:
            prompt = build_prompt(
                final_make, final_model, final_sub_model,
                final_year, final_fuel, final_trans, final_mileage
            )
            model_output = call_model_with_retry(prompt)
        except Exception as e:
            return make_error_response("×©×’×™××ª AI ×‘×¢×ª × ×™×ª×•×—. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.", 500, payload=req_obj, exception=e, extra={"where": "analyze_car", "phase": "model_call"})

        model_output, note = apply_mileage_logic(model_output, final_mileage)

        try:
            new_log = SearchHistory(
                user_id=current_user.id,
                make=final_make,
                model=final_model,
                year=final_year,
                mileage_range=final_mileage,
                fuel_type=final_fuel,
                transmission=final_trans,
                req_hash=req_hash,
                result_json=json.dumps(model_output, ensure_ascii=False),
            )
            db.session.add(new_log)
            db.session.commit()
        except Exception as e:
            db.session.rollback()
            report_problem("Failed to save SearchHistory", 500, exception=e, extra={"where": "analyze_car", "phase": "db_save"})

        model_output["source_tag"] = "××§×•×¨: × ×™×ª×•×— AI ×—×“×©"
        model_output["mileage_note"] = note
        model_output["km_warn"] = False
        return jsonify(model_output)

    # ===========================
    # Error handlers
    # ===========================
    @app.errorhandler(CSRFError)
    def handle_csrf_error(e):
        if _is_api_path():
            return make_error_response("×©×’×™××ª ××‘×˜×—×” (CSRF). ×¨×¢× ×Ÿ ××ª ×”×“×£ ×•× ×¡×” ×©×•×‘.", 403, exception=e, extra={"where": "CSRFError"})
        return redirect(url_for("index"))

    @app.errorhandler(429)
    def handle_429(e):
        # This handler is for Limiter's 429 only. Manual quota 429 responses bypass this.
        if _is_api_path():
            return make_error_response("×”×’×¢×ª ×œ××’×‘×œ×ª ×‘×§×©×•×ª. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.", 429, exception=e, extra={"where": "RateLimit"})
        return "Too Many Requests", 429

    @app.errorhandler(HTTPException)
    def handle_http_exception(e):
        if _is_api_path():
            code = int(getattr(e, "code", 500) or 500)
            msg = getattr(e, "description", None) or "×©×’×™××ª ×‘×§×©×”"
            return make_error_response(msg, code, exception=e, extra={"where": "HTTPException"})
        return e

    @app.errorhandler(Exception)
    def handle_exception(e):
        if _is_api_path():
            return make_error_response("×©×’×™××ª ×©×¨×ª ×¤× ×™××™×ª", 500, exception=e, extra={"where": "UnhandledException"})
        report_problem("Unhandled non-API exception", 500, exception=e, extra={"where": "UnhandledException", "path": request.path})
        return "Internal Server Error", 500

    return app


if __name__ == "__main__":
    app = create_app()
    port = int(os.environ.get("PORT", 5001))
    debug = (os.environ.get("FLASK_DEBUG", "").lower() in ("1", "true", "yes")) and (not _is_render())
    app.run(host="0.0.0.0", port=port, debug=debug)
